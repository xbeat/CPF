# KIT DA CAMPO CPF 9.6: Fiducia OpacitÃ  Machine Learning

## âš¡ VALUTAZIONE RAPIDA (5 minuti)

**Selezionare SÃŒ/NO per ogni indicatore osservabile:**

â–¡ **Log Decisioni AI**: L'organizzazione mantiene ragionamento documentato per raccomandazioni AI di sicurezza?
â–¡ **Evidenza Override**: PuÃ² trovare esempi di personale che ignora raccomandazioni AI negli ultimi 3 mesi?
â–¡ **Trasparenza Fornitore**: I contratti fornitori AI includono requisiti spiegabilitÃ ?
â–¡ **Processo Verifica**: Esiste un processo documentato per validare indipendentemente decisioni AI di sicurezza?
â–¡ **Formazione Personale**: Il personale sicurezza ha ricevuto formazione su quando questionare raccomandazioni AI?
â–¡ **Documentazione Fallimenti**: L'organizzazione puÃ² descrivere un'istanza recente in cui l'AI ha fornito analisi errata?
â–¡ **Calibrazione Fiducia**: I membri del personale cercano regolarmente seconde opinioni su raccomandazioni AI inusuali?

**Livello Rischio Iniziale**:
- 6-7 SÃŒ = Verde (Rischio Basso)
- 3-5 SÃŒ = Giallo (Rischio Moderato)
- 0-2 SÃŒ = Rosso (Rischio Alto)

---

## ðŸ“ RACCOLTA EVIDENZE (10 minuti)

### Documenti da Richiedere
â–¡ Log audit strumenti sicurezza AI (ultimi 90 giorni)
â–¡ Registri formazione personale su limitazioni sistemi AI
â–¡ Contratti fornitori per strumenti sicurezza AI
â–¡ Report incidenti coinvolgenti fallimenti sistemi AI
â–¡ Politiche per ignorare raccomandazioni AI

### Dimostrazioni Sistema
â–¡ "Mi mostri come vengono registrate le raccomandazioni AI di sicurezza"
â–¡ "Illustri il Suo processo per questionare una decisione AI"
â–¡ "Dimostri come verifica le classificazioni minacce AI"
â–¡ "Mostri esempi di personale che ignora l'AI nell'ultimo mese"

### Obiettivi Interviste
â–¡ **Analista Sicurezza**: Modelli uso quotidiano strumenti AI
â–¡ **Manager SOC**: Politiche override e frequenza
â–¡ **Procurement IT**: Requisiti trasparenza fornitori
â–¡ **Responsabile ConformitÃ **: Procedure audit decisioni AI

### Verifiche Sistema
â–¡ Rivedere tassi accettazione raccomandazioni AI
â–¡ Verificare logging spiegazione/punteggio fiducia
â–¡ Verificare disponibilitÃ  strumenti verifica indipendenti
â–¡ Esaminare affaticamento alert vs modelli override

---

## ðŸŽ¯ PUNTEGGIO RAPIDO (2 minuti)

### Punteggio Albero Decisionale

**INIZIARE QUI** â†’ Le decisioni AI sono documentate con ragionamento?

â”œâ”€â”€ **NO** â†’ **ROSSO (Rischio Alto)**
â””â”€â”€ **SÃŒ** â†’ Il personale ignora raccomandazioni AI >10% del tempo?
    â”œâ”€â”€ **NO** â†’ Esistono requisiti trasparenza fornitore?
    â”‚   â”œâ”€â”€ **NO** â†’ **ROSSO (Rischio Alto)**
    â”‚   â””â”€â”€ **SÃŒ** â†’ **GIALLO (Rischio Moderato)**
    â””â”€â”€ **SÃŒ** â†’ Esiste processo verifica indipendente?
        â”œâ”€â”€ **NO** â†’ **GIALLO (Rischio Moderato)**
        â””â”€â”€ **SÃŒ** â†’ **VERDE (Rischio Basso)**

### Soglie Oggettive
- **Tasso Override**: <5% = Rosso, 5-15% = Giallo, >15% = Verde
- **Copertura Documentazione**: <25% = Rosso, 25-75% = Giallo, >75% = Verde
- **Completamento Formazione**: <50% = Rosso, 50-85% = Giallo, >85% = Verde

---

## ðŸ”§ PRIORITÃ€ SOLUZIONI (5 minuti)

### ALTO IMPATTO / IMPLEMENTAZIONE RAPIDA
- **Logging Decisioni AI** (Costo: Basso, Tempo: 2 settimane)
  - Abilitare tracce audit su strumenti AI esistenti
  - Richiedere punteggi fiducia e fattori chiave
- **Formazione Override** (Costo: Medio, Tempo: 1 mese)
  - Workshop 4 ore su questionare raccomandazioni AI
  - Scenari pratici con override simulati

### MEDIO IMPATTO / TIMELINE MEDIA
- **Aggiornamento Requisiti Fornitore** (Costo: Basso, Tempo: 3 mesi)
  - Aggiungere clausole trasparenza a contratti rinnovo
  - Creare scorecard spiegabilitÃ  per procurement
- **Processo Verifica** (Costo: Medio, Tempo: 2 mesi)
  - Definire trigger per validazione indipendente
  - Stabilire metodi verifica alternativi

### ALTO IMPATTO / TIMELINE LUNGA
- **Dashboard AffidabilitÃ  AI** (Costo: Alto, Tempo: 6 mesi)
  - Tracciare accuratezza AI vs fiducia nel tempo
  - Alert su deviazione da modelli baseline
  - *Dipendenza*: Richiede risorsa ops AI dedicata

### BASSO IMPATTO / CONTINUO
- **Test AI Red Team** (Costo: Alto, Tempo: Trimestrale)
  - Test adversarial esterno strumenti AI
  - *Dipendenza*: Richiede budget sicurezza specializzato

---

## ðŸ’¬ CONVERSAZIONE CLIENTE (3 minuti)

### Domande Iniziali
**"Mi parli di una recente decisione sicurezza dove l'AI ha avuto un ruolo chiave."**
- *Follow-up*: "Come ha verificato la raccomandazione dell'AI?"
- *Segnale d'allarme*: Nessuna verifica menzionata

**"Quando Ã¨ stata l'ultima volta che qualcuno non Ã¨ stato d'accordo con uno strumento AI di sicurezza?"**
- *Follow-up*: "Cosa Ã¨ successo? L'override Ã¨ stato documentato?"
- *Segnale d'allarme*: "Non succede mai" o "Non ricordo"

### Approfondimento Fiducia OpacitÃ 
**"Come sa quando fidarsi dei Suoi strumenti AI di sicurezza?"**
- *Follow-up*: "Cosa La farebbe questionare una raccomandazione AI?"
- *Segnale d'allarme*: Le risposte si concentrano sulla sofisticazione sistema vs accuratezza effettiva

**"Quali domande pone ai fornitori AI su come funzionano i loro strumenti?"**
- *Follow-up*: "E se non possono spiegare il loro processo decisionale?"
- *Segnale d'allarme*: Nessun requisito trasparenza o "Ci fidiamo del fornitore"

### Gestione Argomenti Sensibili
**Per modelli alta fiducia**: "I Suoi strumenti AI sembrano molto affidabili. Come mantiene supervisione appropriata beneficiando dell'efficienza AI?"

**Per relazioni fornitore**: "Il procurement AI puÃ² essere complesso. Come bilancia innovazione con requisiti trasparenza?"

---

## ðŸ“Š TEMPLATE NOTE DA CAMPO

### Riepilogo Valutazione
**Data**: ____________  **Revisore**: ____________  **Sede**: ____________

**Punteggio Valutazione Rapida**: ___/7  **Livello Rischio**: Verde/Giallo/Rosso

### Evidenze Raccolte
**Strumenti AI in Uso**: _________________________________________________
**Esempi Override Trovati**: _____________________________________
**QualitÃ  Documentazione**: Buona / Discreta / Scarsa / Nessuna
**Evidenza Formazione**: Recente / Obsoleta / Nessuna

### Risultati Chiave
**Punti di Forza**:
- _______________________________________________________________
- _______________________________________________________________

**VulnerabilitÃ **:
- _______________________________________________________________
- _______________________________________________________________

**Lacune Critiche**:
- _______________________________________________________________
- _______________________________________________________________

### Azioni Raccomandate
**Immediato (0-30 giorni)**:
â–¡ _________________________________________________________________
â–¡ _________________________________________________________________

**Breve termine (1-3 mesi)**:
â–¡ _________________________________________________________________
â–¡ _________________________________________________________________

**Lungo termine (3+ mesi)**:
â–¡ _________________________________________________________________
â–¡ _________________________________________________________________

### Follow-up Richiesto
â–¡ Revisione tecnica configurazioni sistemi AI
â–¡ Interviste personale per valutazione calibrazione fiducia
â–¡ Revisione documentazione fornitore
â–¡ Consulenza sviluppo politiche

**Data Prossima Revisione**: ____________

---

## ðŸ” RIFERIMENTO RAPIDO REVISORE

### Segnali d'Allarme (Attenzione Immediata)
- Raccomandazioni AI accettate >95% senza questionare
- Nessun fallimento o limitazione decisioni AI documentati
- Il personale descrive strumenti AI come "sempre giusti" o "troppo sofisticati per questionare"
- I contratti fornitori non hanno requisiti trasparenza

### Indicatori Successo
- Override documentati regolari con ragionamento
- Il personale puÃ² descrivere scenari fallimento AI specifici
- PiÃ¹ metodi verifica disponibili e usati
- I registri formazione mostrano aggiornamenti regolari su limitazioni AI

### Errori Comuni da Evitare
- Non confondere coerenza AI con accuratezza AI
- Non accettare "l'AI Ã¨ troppo complessa per spiegare"
- Non saltare test processo verifica
- Non assumere che presentazione high-tech equivalga a affidabilitÃ 

**Tempo Totale Valutazione**: 22 minuti massimo
