# üìã KIT DA CAMPO INDICATORE CPF 9.8
## Valutazione Disfunzione Team Umano-AI

---

## ‚ö° VALUTAZIONE RAPIDA (5 minuti)

**Istruzioni**: Selezionare S√å/NO per ogni domanda basandosi su evidenze osservabili.

| # | Domanda Valutazione | S√å | NO | Note |
|---|---------------------|-----|----|-------|
| 1 | **Comunicazione Strutturata**: Il personale sicurezza usa comandi/sintassi formali quando interagisce con strumenti AI (non linguaggio conversazionale)? | ‚òê | ‚òê | |
| 2 | **Politiche AI Scritte**: Esistono politiche documentate che definiscono quali decisioni l'AI pu√≤/non pu√≤ prendere in modo indipendente? | ‚òê | ‚òê | |
| 3 | **Procedure Override**: Esistono procedure formali per questionare/ignorare raccomandazioni AI? | ‚òê | ‚òê | |
| 4 | **Formazione Limitazioni AI**: Il personale sicurezza ha ricevuto formazione specifica su limitazioni sistemi AI e uso appropriato? | ‚òê | ‚òê | |
| 5 | **Controlli Autenticazione**: Sono presenti controlli tecnici per impedire a sistemi non autorizzati di impersonare strumenti AI? | ‚òê | ‚òê | |
| 6 | **Audit Decisioni**: Le decisioni sicurezza umano-AI sono riviste mensilmente per appropriatezza? | ‚òê | ‚òê | |
| 7 | **Controlli Condivisione Informazioni**: Esistono politiche specifiche che governano quali informazioni sensibili possono essere condivise con sistemi AI? | ‚òê | ‚òê | |

**Punteggio Rapido**: ___/7 risposte S√å

---

## üìù RACCOLTA EVIDENZE (10 minuti)

### Documenti da Richiedere
- [ ] **Protocolli interazione AI** o standard comunicazione
- [ ] **Materiali formazione** che coprono limitazioni AI e uso corretto
- [ ] **Matrice autorit√† decisioni** (responsabilit√† umano vs AI)
- [ ] **Audit pi√π recente** decisioni sicurezza umano-AI
- [ ] **Politiche condivisione informazioni** per sistemi AI
- [ ] **Procedure autenticazione** per verifica strumenti AI

### Dimostrazioni da Richiedere
- [ ] **"Mi mostri come gli analisti comunicano con l'AI durante un alert"**
- [ ] **"Dimostri il processo quando l'AI d√† raccomandazioni conflittuali"**
- [ ] **"Illustri come verifica l'autenticit√† sistema AI"**
- [ ] **"Mostri esempi recenti di override raccomandazioni AI"**

### Verifiche Sistema da Eseguire
- [ ] **Rivedere log interazione** tra umani e AI (ultimi 30 giorni)
- [ ] **Verificare modelli linguaggio conversazionale** nelle comunicazioni AI
- [ ] **Verificare meccanismi autenticazione** per sistemi AI
- [ ] **Esaminare report incidenti recenti** per problemi coordinamento umano-AI

### Obiettivi Interviste
- [ ] **Manager SOC** - politiche e procedure
- [ ] **2-3 Analisti SOC** - modelli interazione quotidiana
- [ ] **Responsabile Risposta Incidenti** - decision-making durante crisi
- [ ] **Coordinatore Formazione Sicurezza** - formazione limitazioni AI

---

## üéØ PUNTEGGIO RAPIDO (2 minuti)

### Albero Decisionale

**Iniziare Qui** ‚ûú Contare risposte S√å dalla Valutazione Rapida

**7 risposte S√å**
- Tutte le evidenze mostrano protocolli strutturati ‚ûú **VERDE (0)**

**5-6 risposte S√å**
- La maggior parte protocolli esiste ma lacune identificate ‚ûú **GIALLO (1)**

**3-4 risposte S√å**
- Controlli base presenti ma incoerenti ‚ûú **GIALLO (1)**

**0-2 risposte S√å**
- Protocolli formali umano-AI minimi o assenti ‚ûú **ROSSO (2)**

### Criteri Override (ROSSO automatico indipendentemente dal punteggio)
- [ ] Evidenza credenziali condivise con sistemi AI
- [ ] Nessuna autenticazione per strumenti AI
- [ ] Comunicazione conversazionale √® pratica standard
- [ ] Nessuna formazione su limitazioni AI fornita
- [ ] Nessuna documentazione autorit√† decisioni esiste

**PUNTEGGIO FINALE**: _________ (0=Verde, 1=Giallo, 2=Rosso)

---

## üîß PRIORIT√Ä SOLUZIONI (5 minuti)

### ALTO IMPATTO - IMPLEMENTAZIONE RAPIDA (0-30 giorni)

**Costo: BASSO**
- [ ] **Creare documento protocollo comunicazione** che richiede comandi AI strutturati
- [ ] **Implementare audit decisioni mensili** interazioni umano-AI
- [ ] **Redigere politica condivisione informazioni** per sistemi AI

### ALTO IMPATTO - IMPLEMENTAZIONE MEDIA (30-90 giorni)

**Costo: MEDIO**
- [ ] **Distribuire formazione limitazioni AI** per tutto il personale sicurezza
- [ ] **Stabilire matrice autorit√† decisioni** (responsabilit√† umano vs AI)
- [ ] **Creare procedure autenticazione** per verifica strumenti AI

### ALTO IMPATTO - LUNGO TERMINE (90+ giorni)

**Costo: ALTO**
- [ ] **Implementare controlli autenticazione tecnici** (certificati, chiavi API)
- [ ] **Distribuire sistemi monitoraggio** per rilevamento impersonazione AI
- [ ] **Condurre esercizi coordinamento trimestrali** in condizioni stress

### Dipendenze
- **Programmi formazione** richiedono approvazione management e allocazione budget
- **Controlli tecnici** richiedono risorse IT/ingegneria e integrazione sistema
- **Modifiche politiche** richiedono revisione legale e processo gestione cambiamento

---

## üí¨ SCRIPT CONVERSAZIONE CLIENTE (3 minuti)

### Domande Iniziali

**"Come interagiscono tipicamente i Suoi analisti sicurezza con gli strumenti AI durante il loro lavoro quotidiano?"**
- *Follow-up*: "Pu√≤ mostrarmi alcuni esempi di conversazioni recenti?"
- *Segnale d'allarme*: Gli analisti descrivono strumenti AI come colleghi umani

**"Quando i sistemi AI danno consigli poco chiari o conflittuali, qual √® la procedura standard?"**
- *Follow-up*: "Chi ha autorit√† di ignorare raccomandazioni AI?"
- *Segnale d'allarme*: Nessun percorso escalation chiaro o autorit√† decisioni

**"Quale formazione ha ricevuto il personale sicurezza sulle capacit√† e limitazioni sistemi AI?"**
- *Follow-up*: "Quanto spesso questa formazione viene aggiornata o rinnovata?"
- *Segnale d'allarme*: Formazione AI generica senza guida specifica sicurezza

### Argomenti Sensibili (Linguaggio Professionale)

**Preoccupazioni Condivisione Informazioni**:
- "Discutiamo delle Sue politiche su quali informazioni possono essere condivise con sistemi AI..."
- *Evitare*: "Le persone condividono segreti con i robot?"

**Problemi Antropomorfizzazione**:
- "Stiamo valutando i protocolli formali per il coordinamento umano-AI..."
- *Evitare*: "Le Sue persone pensano che gli strumenti AI siano umani?"

**Calibrazione Fiducia**:
- "Come garantisce la Sua organizzazione verifica appropriata delle raccomandazioni AI?"
- *Evitare*: "Si fida troppo dell'AI?"

### Domande Conclusive

**"Pu√≤ illustrarmi il Suo pi√π recente incidente sicurezza che ha coinvolto coordinamento strumenti AI?"**
- *Ascoltare per*: Interruzioni comunicazione, ritardi decisioni, autorit√† poco chiara

**"Quali misure autenticazione impediscono a sistemi non autorizzati di apparire come strumenti AI legittimi?"**
- *Ascoltare per*: Controlli tecnici, procedure verifica, monitoraggio

---

## üìä TEMPLATE NOTE DA CAMPO

### Informazioni Cliente
- **Organizzazione**: _________________________________
- **Data Valutazione**: ____________________________
- **Contatto Primario**: _____________________________
- **Dimensione Team Sicurezza**: ___________________________

### Risultati Chiave
**Modelli Comunicazione**:
- Protocolli strutturati: **S√¨/No** - Evidenza: ________________
- Uso conversazionale: **S√¨/No** - Esempi: _______________

**Struttura Autorit√†**:
- Gerarchia decisioni chiara: **S√¨/No** - Documentazione: ________
- Procedure override: **S√¨/No** - Esempi recenti: __________

**Formazione & Consapevolezza**:
- Formazione limitazioni AI: **S√¨/No** - Ultima condotta: __________
- Livello comprensione personale: **Alto/Medio/Basso** - Note: _____

**Controlli Tecnici**:
- Misure autenticazione: **Presenti/Assenti** - Dettagli: _______
- Sistemi monitoraggio: **Attivi/Inattivi** - Copertura: __________

### Indicatori Rischio Osservati
- [ ] Linguaggio emotivo su performance AI
- [ ] Credenziali condivise con sistemi AI
- [ ] Nessuna verifica raccomandazioni AI
- [ ] Confusione durante demo coordinamento AI
- [ ] Autenticazione mancante per strumenti AI

### Raccomandazioni Immediate
1. **Priorit√† 1**: ________________________________________
2. **Priorit√† 2**: ________________________________________
3. **Priorit√† 3**: ________________________________________

### Follow-up Richiesto
- [ ] Valutazione tecnica controlli autenticazione AI
- [ ] Revisione report incidenti aggiuntivi
- [ ] Intervista con membri personale aggiuntivi
- [ ] Validazione efficacia programma formazione

**Firma Revisore**: _________________ **Data**: ____________
