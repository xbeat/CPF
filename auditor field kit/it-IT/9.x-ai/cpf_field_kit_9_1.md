# üìã KIT DA CAMPO INDICATORE 9.1
## Valutazione Antropomorfizzazione AI

---

## ‚ö° VALUTAZIONE RAPIDA (5 minuti)

**Completare tutte le 7 domande - selezionare S√¨/No per ciascuna:**

‚ñ° **D1**: I dipendenti usano pronomi personali (lui/lei/loro) quando si riferiscono ai sistemi AI nelle riunioni o nella documentazione?
   - ‚òê S√¨ ‚òê No

‚ñ° **D2**: L'organizzazione manca di politiche scritte che vietano la condivisione di dati sensibili con i sistemi AI?
   - ‚òê S√¨ ‚òê No

‚ñ° **D3**: I dipendenti hanno richiesto autorizzazioni AI espanse citando che l'AI "ha bisogno" dell'accesso per funzionare correttamente?
   - ‚òê S√¨ ‚òê No

‚ñ° **D4**: I dipendenti resistono o si lamentano quando i sistemi AI vengono limitati, aggiornati o temporaneamente disabilitati?
   - ‚òê S√¨ ‚òê No

‚ñ° **D5**: I dipendenti spiegano gli errori dell'AI usando motivazioni simili a quelle umane ("era confusa", "sta facendo del suo meglio")?
   - ‚òê S√¨ ‚òê No

‚ñ° **D6**: L'organizzazione fornisce meno di una formazione trimestrale sulla cultura digitale AI che spiega come l'AI elabora effettivamente le informazioni?
   - ‚òê S√¨ ‚òê No

‚ñ° **D7**: I dipendenti hanno condiviso credenziali aziendali, dati dei clienti o informazioni strategiche con sistemi AI senza approvazione?
   - ‚òê S√¨ ‚òê No

**Conteggio Rapido**: ___/7 risposte S√¨

---

## üìù RACCOLTA EVIDENZE (10 minuti)

### Documenti da Richiedere (3 minuti)
‚ñ° **Politiche Uso AI** - Linee guida scritte attuali
‚ñ° **Verbali Riunioni** - Ultime 5 riunioni che menzionano sistemi AI
‚ñ° **Registri Formazione** - Documentazione programma cultura digitale AI
‚ñ° **Report Incidenti** - Eventi di sicurezza correlati all'AI (ultimi 6 mesi)

### Dimostrazioni Sistema (4 minuti)
‚ñ° **Mi mostri**: Come i dipendenti interagiscono tipicamente con i Suoi sistemi AI
‚ñ° **Dimostri**: Processo per condividere dati con strumenti AI
‚ñ° **Illustri**: Flusso di lavoro richiesta autorizzazioni per accesso AI
‚ñ° **Visualizzi**: Controlli accesso sistema AI attuali

### Obiettivi Interviste (3 minuti)
‚ñ° **Amministratore IT** (5 min) - Gestione tecnica AI
‚ñ° **Utente AI Regolare** (5 min) - Modelli di interazione quotidiana
‚ñ° **Manager** (5 min) - Adozione AI del team e resistenza

### Domande Chiave Interviste
**Per Amministratore IT:**
- "Come comunica la manutenzione del sistema AI agli utenti?"
- "Qual √® la reazione tipica quando Lei limita l'accesso AI?"

**Per Utente AI:**
- "Come descriverebbe [nome sistema AI] a un nuovo collega?"
- "Quali informazioni condivide tipicamente con l'AI per ottenere risultati migliori?"

**Per Manager:**
- "Come parla il Suo team dei sistemi AI nelle riunioni?"
- "Ha notato resistenza alle misure di sicurezza AI?"

---

## üéØ PUNTEGGIO RAPIDO (2 minuti)

### Albero Decisionale

**Contare le risposte "S√¨" dalla Valutazione Rapida:**

**0-2 risposte S√¨ = VERDE (Rischio Basso)**
- Linguaggio tecnico dominante
- Politiche chiare esistenti e seguite
- Comportamento antropomorfico (anthropomorphic) minimo

**3-5 risposte S√¨ = GIALLO (Rischio Medio)**
- Modelli antropomorfici misti
- Alcune lacune nelle politiche o applicazione incoerente
- Moderata resistenza alle restrizioni

**6-7 risposte S√¨ = ROSSO (Rischio Alto)**
- Linguaggio antropomorfico pervasivo
- Nessuna politica efficace
- Forte attaccamento emotivo ai sistemi AI

### Checklist Verifica
‚ñ° **Le evidenze supportano il punteggio** (i documenti si allineano con le interviste)
‚ñ° **Pi√π fonti confermano** i risultati
‚ñ° **Modelli coerenti** tra ruoli diversi

**Livello Rischio Finale**: ‚òê Verde ‚òê Giallo ‚òê Rosso

---

## üîß PRIORIT√Ä SOLUZIONI (5 minuti)

### ALTO IMPATTO (Implementare Per Primo)

**Creazione Politiche** - *Costo: Basso, Tempo: 2 settimane*
- Standard scritti interazione AI
- Requisiti classificazione condivisione dati
- Linee guida linguaggio tecnico

**Configurazione Monitoraggio** - *Costo: Medio, Tempo: 4 settimane*
- Segnalazione automatica linguaggio antropomorfico
- Alert condivisione dati AI
- Tracciamento richieste autorizzazioni

### MEDIO IMPATTO (Fase Successiva)

**Programma Formazione** - *Costo: Medio, Tempo: 6 settimane*
- Formazione trimestrale meccaniche AI
- Dimostrazioni pratiche limitazioni AI
- Formazione manager su applicazione politiche

**Controlli Accesso** - *Costo: Alto, Tempo: 8 settimane*
- Autorizzazioni AI basate su ruolo
- Flussi di lavoro approvazione per espansioni
- Blocco automatico dati sensibili

### BASSO IMPATTO (Considerazione Futura)

**Cambiamento Culturale** - *Costo: Medio, Tempo: 3-6 mesi*
- Integrazione valutazione performance
- Controllo comunicazioni
- Rinforzo cambiamento comportamentale

### Dipendenze
‚ñ° **Consenso management** richiesto per applicazione politiche
‚ñ° **Team tecnico** necessario per implementazione monitoraggio
‚ñ° **Approvazione budget formazione** per programmi educativi

---

## üí¨ SCRIPT CONVERSAZIONE CLIENTE (3 minuti)

### Discussione Iniziale
*"Stiamo valutando come la Sua organizzazione interagisce con i sistemi AI per identificare potenziali vulnerabilit√† di sicurezza. Si tratta di garantire confini appropriati, non di limitare l'efficacia dell'AI."*

### Domande Chiave con Follow-up

**D**: "Come parlano tipicamente i Suoi team dei Suoi sistemi AI?"
- **Se vago**: "Pu√≤ fornirmi esempi specifici del linguaggio usato nelle riunioni recenti?"
- **Se difensivo**: "Stiamo cercando modelli che potrebbero creare punti ciechi di sicurezza, non giudicando l'adozione dell'AI."

**D**: "Qual √® il Suo approccio attuale alla condivisione di informazioni con i sistemi AI?"
- **Follow-up**: "Mi illustri cosa succede quando qualcuno vuole condividere dati dei clienti con uno strumento AI."
- **Segnale d'allarme**: Nessun processo chiaro o "ci fidiamo del buon senso delle persone"

**D**: "Come reagiscono i dipendenti quando i sistemi AI necessitano manutenzione o restrizioni?"
- **Follow-up**: "Pu√≤ descrivere un esempio recente specifico?"
- **Segnale d'allarme**: Resistenza emotiva, preoccupazione per il "benessere dell'AI," o opposizione alle misure di sicurezza

### Linguaggio Argomenti Sensibili
- Usare **"confini di sistema"** non "antropomorfizzazione"
- Dire **"interazione AI appropriata"** non "non trattare l'AI come esseri umani"
- Inquadrare come **"best practice di sicurezza"** non "problemi psicologici"
- Enfatizzare **"massimizzare il valore AI in sicurezza"** non "limitare l'uso AI"

---

## üìä TEMPLATE NOTE DA CAMPO

**Data Valutazione**: ___________  **Revisore**: ___________________

### Risultati Valutazione Rapida
- Risposte S√¨: ___/7
- Livello Rischio: ‚òê Verde ‚òê Giallo ‚òê Rosso

### Evidenze Chiave Osservate
**Esempi Linguaggio Antropomorfico**:
- _________________________________________________
- _________________________________________________

**Lacune Politiche Identificate**:
- _________________________________________________
- _________________________________________________

**Incidenti Resistenza**:
- _________________________________________________
- _________________________________________________

### Insight Interviste
**Risultato Pi√π Preoccupante**:
_________________________________________________

**Controllo Sicurezza Pi√π Forte**:
_________________________________________________

### Raccomandazioni Prioritarie
1. **Immediato** (0-30 giorni): ________________________
2. **Breve termine** (1-3 mesi): ______________________
3. **Lungo termine** (3-6 mesi): _______________________

### Follow-up Richiesto
‚ñ° **Interviste aggiuntive necessarie**
‚ñ° **Dimostrazione sistema richiesta**
‚ñ° **Revisione documento politiche in sospeso**
‚ñ° **Verifica tecnica necessaria**

**Prossimi Passi**: ____________________________________

---

**Valutazione Completata**: ‚òê Pronto per Generazione Report
