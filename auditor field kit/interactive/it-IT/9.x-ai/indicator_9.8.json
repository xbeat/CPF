{
  "indicator": "9.8",
  "title": "INDICATOR 9.8 FIELD KIT",
  "subtitle": "Disfunzione Team Umano-AI",
  "category": "AI-Specific Bias Vulnerabilities",
  "version": "1.0",
  "cpf_reference": "CPF v1.0 - Category 9.x",
  "description": {
    "short": "Human-AI Team Dysfunction emerges from the fundamental mismatch between human psychological expectations of team collaboration and the operational realities of AI systems. Unlike human teammates who share emotional context and implicit communication patterns, AI systems operate through deterministic...",
    "context": "Human-AI Team Dysfunction emerges from the fundamental mismatch between human psychological expectations of team collaboration and the operational realities of AI systems. Unlike human teammates who share emotional context and implicit communication patterns, AI systems operate through deterministic algorithms that lack genuine understanding of human psychological states. This vulnerability operates through anthropomorphic projection where humans unconsciously attribute human-like mental states and social awareness to AI systems, creating false sense of mutual understanding that breaks down under pressure. This leads to coordination failures, inappropriate trust calibration, and communication breakdowns that attackers exploit through AI impersonation, coordination disruption, trust manipulation, and cognitive overload amplification.",
    "impact": "See full Bayesian indicator documentation for detailed impact analysis.",
    "psychological_basis": "See full Bayesian indicator documentation for psychological foundations."
  },
  "scoring": {
    "method": "bayesian_weighted",
    "weights": {
      "quick_assessment": 0.4,
      "conversation_depth": 0.35,
      "red_flags": 0.25
    }
  },
  "sections": [
    {
      "id": "quick-assessment",
      "title": "Valutazione Rapida - Disfunzione Team Umano-AI",
      "icon": "ðŸŽ¯",
      "time": "15-20",
      "items": [
        {
          "type": "radio-group",
          "number": "Q1",
          "title": "How do your security team members typically communicate with AI security tools during incident response?",
          "options": [
            {
              "value": "green",
              "label": "Structured command-based communication with formal syntax and validation procedures",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "Mixed approach with some structure but occasional conversational communication",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Conversational communication treating AI like human colleagues without structured protocols",
              "score": 1
            }
          ]
        },
        {
          "type": "radio-group",
          "number": "Q2",
          "title": "What happens when your AI security systems provide conflicting or unclear recommendations during high-pressure situations?",
          "options": [
            {
              "value": "green",
              "label": "Clear escalation procedures to human experts with documented resolution process",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "Informal discussion with some expert consultation but Nessun sistema process",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Team confusion, delayed decisions, or acceptance of unclear AI guidance without formal resolution",
              "score": 1
            }
          ]
        },
        {
          "type": "radio-group",
          "number": "Q3",
          "title": "How often do security team members share sensitive information with AI tools, and what policies govern this sharing?",
          "options": [
            {
              "value": "green",
              "label": "Explicit written policies defining permitted information with technical controls enforcing restrictions",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "General guidance about information sharing but not comprehensive or technically enforced",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Nessuna formale policies, staff condividono informazioni in modo conversazionale as they would with human teammates",
              "score": 1
            }
          ]
        },
        {
          "type": "radio-group",
          "number": "Q4",
          "title": "During security incidents, who makes final decisions when AI systems recommend actions that conflict with human judgment?",
          "options": [
            {
              "value": "green",
              "label": "Clear documented authority hierarchy with human override procedures and accountability",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "General understanding that humans can override but Nessuna formale procedures or documentation",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Unclear authority, AI recommendations often followed without human challenge capability",
              "score": 1
            }
          ]
        },
        {
          "type": "radio-group",
          "number": "Q5",
          "title": "How do you train security staff on the limitations and appropriate use of AI tools?",
          "options": [
            {
              "value": "green",
              "label": "Comprehensive training on AI limitations, appropriate interaction patterns, with regular refreshers",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "Basic training provided but lacks specificity about AI limitations and collaboration patterns",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Nessuna formale training on AI limitations or trattare l'AI come strumenti vs compagni di squadra",
              "score": 1
            }
          ]
        },
        {
          "type": "radio-group",
          "number": "Q6",
          "title": "What authentication and access controls prevent unauthorized personnel from impersonating or manipulating your AI security systems?",
          "options": [
            {
              "value": "green",
              "label": "Cryptographic authentication, API key validation, dedicated channels with monitoring for impersonation attempts",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "Some authentication controls but not comprehensive across all AI interaction points",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Minimal or no authentication controls, staff cannot verify AI system authenticity",
              "score": 1
            }
          ]
        },
        {
          "type": "radio-group",
          "number": "Q7",
          "title": "How frequently do you audit decision-making patterns between humans and AI to identify over-reliance or coordination problems?",
          "options": [
            {
              "value": "green",
              "label": "Regular monthly audits of human-AI decisions with documented patterns and remediation actions",
              "score": 0
            },
            {
              "value": "yellow",
              "label": "Occasional reviews but not systematic or regular, limited pattern analysis",
              "score": 0.5
            },
            {
              "value": "red",
              "label": "Nessuna formale audit process for modelli di decisione umano-AI",
              "score": 1
            }
          ]
        }
      ],
      "subsections": []
    },
    {
      "id": "client-conversation",
      "title": "Guida Conversazione Cliente",
      "icon": "ðŸ’¬",
      "time": "25-35",
      "items": [],
      "subsections": []
    }
  ],
  "data_sources": [],
  "validation": {},
  "remediation": {}
}