{
  "indicator": "10.2",
  "title": "INDICATOR 10.2 FIELD KIT",
  "subtitle": "Cascade Failure Triggers",
  "category": "AI-Specific Bias Vulnerabilities",
  "version": "1.0",
  "cpf_reference": "CPF v1.0 - Category 9.x",
  "description": {
    "short": "Detects psychological conditions where isolated security incidents spread throughout organizations like wildfire through stress contagion, communication breakdown, and decision-making degradation",
    "context": "Cascade failure triggers occur when organizational stress causes isolated security incidents to propagate across departments through psychological contagion. When one person or team becomes overwhelmed during a crisis, their panic, poor decisions, or communication breakdown creates a domino effect that disables security controls across multiple departments. This psychological contagion transforms minor incidents into major breaches because stressed employees bypass procedures, make configuration errors, and fail to coordinate responses effectively.",
    "impact": "Organizations experiencing cascade failures face multi-vector attacks during operational stress, social engineering campaigns during legitimate crisis periods, insider threat amplification during organizational turmoil, and supply chain attacks via vendor crisis exploitation. Historical examples include Target 2013 (holiday stress + vendor chaos + POS deployment enabled both HVAC compromise and data exfiltration), Equifax 2017 (vulnerability + organizational dysfunction + discovery panic triggered contradictory decisions), and COVID-19 remote work transition (IT overwhelm + expanded attack surface + employee anxiety created widespread security blind spots).",
    "psychological_basis": "Emotional Contagion Studies (Hatfield et al., 1994) demonstrate emotions spread automatically through organizations within minutes. Stress Contagion Research (Westman, 2001) shows stress transfers between individuals through multiple mechanisms. Mirror Neuron Systems enable automatic replication of observed stress behaviors. Limbic Resonance (Lewis et al., 2000) shows emotional brain states synchronize between individuals. Bion's Basic Assumptions (1961) reveal groups under stress revert to primitive psychological defenses that cascade through organizational networks."
  },
  "scoring": {
    "method": "bayesian_weighted",
    "formula": "Final_Score = (w1 Ã— Quick_Assessment + w2 Ã— Conversation_Depth + w3 Ã— Red_Flags) Ã— Interdependency_Multiplier",
    "weights": {
      "quick_assessment": 0.4,
      "conversation_depth": 0.35,
      "red_flags": 0.25
    },
    "maturity_levels": {
      "green": {
        "score_range": [
          0,
          0.33
        ],
        "label": "Low Vulnerability - Cascade-Resistant",
        "description": "Formal incident command structure with defined roles. Communication channels remain functional during stress with backup systems. Security exceptions require documented justification and tracking. Leadership communicates transparently during challenges. Clear business continuity plans address cross-department dependencies. Documented succession planning for security decision-making. Structured alert triage process with defined escalation.",
        "risk_level": "low",
        "color": "#22c55e"
      },
      "yellow": {
        "score_range": [
          0.34,
          0.66
        ],
        "label": "Moderate Vulnerability - Partial Resistance",
        "description": "Informal coordination during incidents with some defined processes. Communication strained during stress but doesn't completely break down. Some tracking of security exceptions but approval processes may be bypassed. Leadership communication inconsistent during stress. Some understanding of dependencies but limited contingency plans. Backup decision-makers identified but authority unclear. Alert prioritization exists but may break down under high volume.",
        "risk_level": "medium",
        "color": "#eab308"
      },
      "red": {
        "score_range": [
          0.67,
          1
        ],
        "label": "High Vulnerability - Cascade-Prone",
        "description": "No clear incident coordination structure or ad-hoc responses. Communication channels regularly overloaded or bypassed during stress. Security exceptions approved informally without tracking during urgent situations. Leadership unavailable or visibly stressed during challenges. Limited awareness of cross-department dependencies and cascade risks. No clear backup decision-making authority or conflicting authority during crisis. Alert responses become arbitrary or delayed when team overwhelmed.",
        "risk_level": "high",
        "color": "#ef4444"
      }
    },
    "question_weights": {
      "q1_verification_procedures": 0.17,
      "q2_gut_feeling_protocol": 0.16,
      "q3_verification_frequency": 0.15,
      "q4_discomfort_policy": 0.14,
      "q5_training_ai_detection": 0.13,
      "q6_video_verification": 0.13,
      "q7_escalation_speed": 0.12
    }
  },
  "detection_formula": {
    "type": "cascade_propagation_detection",
    "mathematical_model": {
      "primary": "CFI(t) = Î£(i=1 to N) [Sáµ¢(t) Ã— Cáµ¢ Ã— Páµ¢â±¼]",
      "components": {
        "cascade_failure_index": {
          "formula": "CFI(t) = Î£(i=1 to N) [Sáµ¢(t) Ã— Cáµ¢ Ã— Páµ¢â±¼]",
          "description": "Cascade failure index measuring stress propagation across organizational units",
          "variables": {
            "Sáµ¢(t)": "stress level in unit i at time t (range 0-1)",
            "Cáµ¢": "criticality weight of unit i based on role in security operations",
            "Páµ¢â±¼": "propagation probability from unit i to unit j based on communication patterns"
          }
        },
        "stress_contagion_rate": {
          "formula": "dS/dt = Î² Ã— S(t) Ã— (1 - S(t)) - Î³ Ã— S(t)",
          "description": "Rate of stress contagion propagation through organization (epidemiological model)",
          "variables": {
            "Î²": "transmission rate of stress between organizational units",
            "Î³": "recovery rate from stress state",
            "S(t)": "proportion of organization in stressed state at time t"
          }
        },
        "communication_breakdown_threshold": {
          "formula": "CB(t) = 1 if MsgVol(t) > Î¼_capacity + 2Ïƒ_capacity AND ResponseTime(t) > 2 Ã— Baseline",
          "description": "Binary indicator of communication system failure during stress",
          "thresholds": {
            "message_volume_threshold": "mean capacity + 2 standard deviations",
            "response_time_threshold": "2x baseline response time",
            "combined_threshold": "both conditions must be met"
          }
        },
        "decision_quality_degradation": {
          "formula": "DQD(t) = 1 - exp(-Î» Ã— StressLoad(t))",
          "description": "Decision quality degradation under stress load",
          "variables": {
            "Î»": "degradation rate parameter from empirical analysis",
            "StressLoad(t)": "cumulative stress load index at time t"
          }
        }
      },
      "default_weights": {
        "w1_stress_contagion": 0.4,
        "w2_communication_breakdown": 0.35,
        "w3_decision_degradation": 0.25
      },
      "interpretation": {
        "CFI < 0.3": "Normal operational state - isolated stress contained",
        "0.3 â‰¤ CFI < 0.6": "Elevated cascade risk - implement monitoring and stress relief",
        "CFI â‰¥ 0.6": "Critical cascade conditions - activate incident command center immediately"
      }
    },
    "data_collection_frequency": "continuous during high-stress periods, hourly during normal operations",
    "baseline_establishment": "90-day rolling window with stress period normalization"
  },
  "data_sources": {
    "manual_assessment": {
      "primary": [
        "employee_verification_procedures",
        "gut_feeling_escalation_protocols",
        "ai_communication_training_records",
        "ambiguous_interaction_examples"
      ],
      "evidence_required": [
        "ai_human_verification_policy",
        "uncanny_response_protocols",
        "recent_ambiguous_communication_cases",
        "training_materials_ai_detection"
      ]
    },
    "automated_soc": {
      "required": [
        {
          "source": "communication_verification_logs",
          "fields": [
            "message_id",
            "human_likeness_score",
            "verification_performed",
            "escalation_triggered",
            "outcome"
          ],
          "retention": "90_days"
        },
        {
          "source": "interaction_hesitation_metrics",
          "fields": [
            "user_id",
            "interaction_type",
            "response_time",
            "hesitation_indicators",
            "verification_requests"
          ],
          "retention": "60_days"
        },
        {
          "source": "ai_communication_analysis",
          "fields": [
            "communication_id",
            "ai_confidence",
            "human_cues_present",
            "artificial_cues_detected",
            "uncanny_score"
          ],
          "retention": "180_days"
        }
      ],
      "optional": [
        {
          "source": "employee_discomfort_reports",
          "fields": [
            "report_id",
            "interaction_description",
            "discomfort_level",
            "resolution_action"
          ],
          "retention": "365_days"
        },
        {
          "source": "video_call_verification",
          "fields": [
            "call_id",
            "deepfake_detection_score",
            "verification_triggered",
            "authentication_method"
          ],
          "retention": "90_days"
        }
      ],
      "telemetry_mapping": {
        "TD_trust_disruption": {
          "calculation": "Trust disruption based on human-likeness assessment",
          "query": "SELECT -1 * DERIVATIVE(affinity_score, human_likeness_score) FROM ai_interactions WHERE uncanny_range=true"
        },
        "BI_behavioral": {
          "calculation": "Weighted sum of avoidance behaviors",
          "query": "SELECT SUM(weight * behavior_frequency) FROM avoidance_behaviors WHERE time_window='30d'"
        },
        "Interaction_drop": {
          "calculation": "Reduction in interaction frequency with uncanny AI",
          "query": "SELECT (baseline_frequency - current_frequency) / baseline_frequency FROM interaction_patterns WHERE uncanny_detected=true"
        }
      }
    },
    "integration_apis": {
      "communication_platforms": "Email/Chat APIs - Message Analysis, Human Cue Detection",
      "video_conferencing": "Video Call APIs - Deepfake Detection Integration",
      "nlp_services": "Natural Language Processing - Uncanny Language Pattern Detection",
      "biometric_verification": "Authentication APIs - Multi-Factor Human Verification"
    }
  },
  "interdependencies": {
    "primary": {
      "10.1": {
        "type": "amplified_by",
        "weight": 0.35,
        "description": "Perfect storm conditions create ideal environment for cascade failure triggers to propagate across organizational boundaries",
        "mathematical_relationship": "D_10.1 Ã— D_10.2 > 0.5 indicates high convergent cascade risk"
      },
      "10.3": {
        "type": "triggers",
        "weight": 0.3,
        "description": "Cascade failures push organizations toward tipping points where small additional stressors cause sudden collapse",
        "mathematical_relationship": "CFI > 0.5 reduces tipping point threshold by 30%"
      },
      "10.4": {
        "type": "enables",
        "weight": 0.25,
        "description": "Cascade failures create stress-induced blind spots that align vulnerabilities across defensive layers",
        "mathematical_relationship": "Alignment probability increases by factor (1 + 0.4 Ã— CFI)"
      },
      "10.5": {
        "type": "compounds",
        "weight": 0.1,
        "description": "Black swan blindness prevents recognition of cascade patterns until widespread failure occurs",
        "mathematical_relationship": "D_10.5 > 0.6 delays cascade detection by 24-48 hours"
      }
    },
    "secondary": {
      "7.1": {
        "type": "amplifies",
        "weight": 0.22,
        "description": "Acute stress responses in individuals provide fuel for organizational cascade propagation",
        "mathematical_relationship": "Cascade transmission rate Î² = Î²_baseline Ã— (1 + 0.5 Ã— D_7.1)"
      },
      "2.1": {
        "type": "triggers",
        "weight": 0.18,
        "description": "Urgency-induced bypass decisions create cascade initiation points that spread across teams",
        "mathematical_relationship": "Cascade initiation probability = 0.2 + 0.6 Ã— D_2.1"
      },
      "5.2": {
        "type": "compounds",
        "weight": 0.15,
        "description": "Decision fatigue reduces organizational resistance to cascade propagation",
        "mathematical_relationship": "Cascade resistance = 1 - (0.4 Ã— D_5.2)"
      },
      "3.1": {
        "type": "amplifies",
        "weight": 0.12,
        "description": "Authority compliance patterns create structured pathways for cascade propagation through hierarchies",
        "mathematical_relationship": "Hierarchical cascade multiplier = 1 + (0.3 Ã— D_3.1)"
      }
    }
  },
  "sections": [
    {
      "id": "quick-assessment",
      "icon": "âš¡",
      "title": "QUICK ASSESSMENT",
      "time": 5,
      "type": "radio-questions",
      "scoring_method": "weighted_average",
      "items": [
        {
          "type": "radio-list",
          "number": 1,
          "id": "q1_incident_coordination",
          "weight": 0.18,
          "title": "Question Title",
          "question": "During your last significant IT incident (outage, security alert, or system failure), how many departments were involved in the response and how was coordination managed?",
          "options": [
            {
              "value": "formal_incident_command",
              "label": "Formal incident command structure with pre-defined roles, clear authority, and coordinated response across all involved departments",
              "score": 0,
              "follow_up": "Walk us through how the incident command structure worked in your example."
            },
            {
              "value": "informal_coordination",
              "label": "Informal coordination through meetings and communication; multiple departments involved but coordination was ad-hoc",
              "score": 0.5,
              "follow_up": "How long did it take to establish coordination and what delays occurred?"
            },
            {
              "value": "limited_coordination",
              "label": "Each department responded independently with limited coordination, leading to some conflicting actions or duplicated efforts",
              "score": 0.85,
              "follow_up": "What conflicts or inefficiencies arose from the lack of coordination?"
            },
            {
              "value": "no_coordination",
              "label": "No clear coordination process; responses were chaotic and departments often worked at cross-purposes",
              "score": 1,
              "follow_up": "What were the consequences of the uncoordinated response?"
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        },
        {
          "type": "radio-list",
          "number": 2,
          "id": "q2_communication_crisis",
          "weight": 0.16,
          "title": "Question Title",
          "question": "What happens to your normal communication channels (email, Slack, Teams, meetings) when your organization faces urgent deadlines, major incidents, or leadership changes?",
          "options": [
            {
              "value": "resilient_communication",
              "label": "Communication channels remain functional with backup systems; structured communication protocols prevent overload",
              "score": 0,
              "follow_up": "Describe how backup systems and protocols maintained communication effectiveness."
            },
            {
              "value": "strained_communication",
              "label": "Communication becomes strained and slower but doesn't completely break down; most critical information still flows",
              "score": 0.5,
              "follow_up": "What delays occurred and how did you work around communication bottlenecks?"
            },
            {
              "value": "partial_breakdown",
              "label": "Communication channels become overloaded; people bypass normal channels leading to information gaps and missed messages",
              "score": 0.85,
              "follow_up": "What information was missed and what security implications resulted?"
            },
            {
              "value": "complete_breakdown",
              "label": "Communication breakdown is routine during stress; teams lose visibility into what others are doing",
              "score": 1,
              "follow_up": "Describe the security consequences of the communication breakdown."
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        },
        {
          "type": "radio-list",
          "number": 3,
          "id": "q3_security_overrides",
          "weight": 0.15,
          "title": "Question Title",
          "question": "How often do employees request exceptions to security policies during busy periods, tight deadlines, or crisis situations? Who approves these exceptions and how are they tracked?",
          "options": [
            {
              "value": "formal_tracking",
              "label": "All exceptions require documented justification, formal approval, and are tracked in a system with automatic expiration",
              "score": 0,
              "follow_up": "Show us your exception tracking system and recent approval examples."
            },
            {
              "value": "informal_tracking",
              "label": "Most exceptions are documented and approved but tracking is informal; some exceptions may be extended indefinitely",
              "score": 0.5,
              "follow_up": "What percentage of exceptions are still active beyond their original timeframe?"
            },
            {
              "value": "minimal_tracking",
              "label": "Security exceptions are frequently approved verbally during urgent situations with minimal documentation",
              "score": 0.85,
              "follow_up": "What security gaps have resulted from undocumented exceptions?"
            },
            {
              "value": "no_tracking",
              "label": "Security policies are routinely bypassed during stress periods without formal approval or tracking",
              "score": 1,
              "follow_up": "Describe security incidents that resulted from untracked policy bypasses."
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        },
        {
          "type": "radio-list",
          "number": 4,
          "id": "q4_leadership_visibility",
          "weight": 0.14,
          "title": "Question Title",
          "question": "When your organization faces major challenges (budget cuts, regulatory issues, competitive threats, major incidents), how do senior leaders communicate with staff about the situation?",
          "options": [
            {
              "value": "transparent_communication",
              "label": "Leaders communicate transparently, maintain visible presence, and provide regular updates while acknowledging challenges",
              "score": 0,
              "follow_up": "Describe specific communications and how they affected team confidence."
            },
            {
              "value": "limited_communication",
              "label": "Some leadership communication occurs but inconsistent; teams receive mixed messages or limited information",
              "score": 0.5,
              "follow_up": "How did inconsistent communication affect team stress and decision-making?"
            },
            {
              "value": "visible_stress",
              "label": "Leaders become visibly stressed or anxious during challenges, which spreads concern throughout the organization",
              "score": 0.85,
              "follow_up": "How did visible leadership stress affect organizational response?"
            },
            {
              "value": "leadership_unavailable",
              "label": "Leaders become unavailable or uncommunicative during challenges, leaving teams without direction or reassurance",
              "score": 1,
              "follow_up": "What decisions were delayed or made without leadership input?"
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        },
        {
          "type": "radio-list",
          "number": 5,
          "id": "q5_cross_department_dependencies",
          "weight": 0.13,
          "title": "Question Title",
          "question": "If your IT/security team becomes overwhelmed or unavailable, which other business functions would be immediately impacted? How quickly would problems cascade to other departments?",
          "options": [
            {
              "value": "documented_dependencies",
              "label": "Clear business continuity plans document dependencies with defined isolation procedures to prevent cascades",
              "score": 0,
              "follow_up": "Walk us through how isolation procedures prevented cascade effects in your example."
            },
            {
              "value": "some_awareness",
              "label": "Some understanding of dependencies exists but limited documented contingency plans; cascades are slow (24+ hours)",
              "score": 0.5,
              "follow_up": "Which dependencies lack contingency plans and what risks do they create?"
            },
            {
              "value": "rapid_cascade",
              "label": "Multiple departments would be impacted within hours; limited awareness of how to isolate problems",
              "score": 0.85,
              "follow_up": "Describe how quickly the cascade occurred and which departments were affected."
            },
            {
              "value": "immediate_cascade",
              "label": "IT/security issues immediately cascade to most departments; no isolation procedures exist",
              "score": 1,
              "follow_up": "What business impacts resulted from the cascade?"
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        },
        {
          "type": "radio-list",
          "number": 6,
          "id": "q6_backup_authority",
          "weight": 0.12,
          "title": "Question Title",
          "question": "Who makes security-related decisions when primary decision-makers are unavailable, overwhelmed, or in disagreement during a crisis?",
          "options": [
            {
              "value": "clear_succession",
              "label": "Documented succession planning with clear backup authority and decision rights; backups are trained and empowered",
              "score": 0,
              "follow_up": "Walk us through how backup authority worked in your example."
            },
            {
              "value": "informal_backup",
              "label": "Backup decision-makers identified but authority and scope are unclear; some delays while authority is established",
              "score": 0.5,
              "follow_up": "How long did it take to establish decision authority and what was delayed?"
            },
            {
              "value": "authority_confusion",
              "label": "Conflicting authority during crisis with multiple people claiming decision rights or deferring to others",
              "score": 0.85,
              "follow_up": "How was the authority confusion eventually resolved and what security decisions were delayed?"
            },
            {
              "value": "no_backup",
              "label": "No clear backup authority; decisions are delayed until primary decision-maker is available or made without proper authority",
              "score": 1,
              "follow_up": "What were the consequences of delayed or unauthorized security decisions?"
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        },
        {
          "type": "radio-list",
          "number": 7,
          "id": "q7_alert_degradation",
          "weight": 0.12,
          "title": "Question Title",
          "question": "During busy periods or when multiple alerts occur simultaneously, how does your team prioritize responses? What happens to lower-priority alerts?",
          "options": [
            {
              "value": "structured_triage",
              "label": "Structured alert triage process with defined escalation procedures; all alerts are reviewed even if response is delayed",
              "score": 0,
              "follow_up": "Describe the triage process and how it performed during alert overload."
            },
            {
              "value": "informal_prioritization",
              "label": "Informal prioritization by team members; lower-priority alerts may be delayed but eventually addressed",
              "score": 0.5,
              "follow_up": "What was the maximum delay for lower-priority alerts and were any missed?"
            },
            {
              "value": "arbitrary_selection",
              "label": "Alert responses become arbitrary when team is overwhelmed; some alerts are ignored or dismissed without review",
              "score": 0.85,
              "follow_up": "Were any ignored alerts later found to be significant threats?"
            },
            {
              "value": "alert_paralysis",
              "label": "Team becomes paralyzed by alert volume; systematic response breaks down and alerts are largely ignored",
              "score": 1,
              "follow_up": "What security incidents occurred while the team was in alert paralysis?"
            }
          ],
          "evidence_required": "",
          "soc_mapping": ""
        }
      ],
      "subsections": [],
      "instructions": "Select ONE option for each question. Each answer contributes to the weighted final score. Evidence should be documented for audit trail.",
      "calculation": "Quick_Score = Î£(question_score Ã— question_weight) / Î£(question_weight)"
    },
    {
      "id": "client-conversation",
      "icon": "ðŸ’¬",
      "title": "CLIENT CONVERSATION",
      "time": 15,
      "type": "conversation",
      "scoring_method": "qualitative_depth",
      "items": [],
      "subsections": [
        {
          "title": "Opening Questions - Verification and Discomfort Handling",
          "weight": 0.35,
          "items": [
            {
              "type": "question",
              "id": "conv_q1",
              "text": "How does your organization handle verification when employees receive communications from AI systems or chatbots (customer service bots, automated assistants, AI-generated emails)? Tell us your specific example of a recent AI interaction that required verification.",
              "scoring_guidance": {
                "green": "Clear verification procedures with specific recent example showing effective handling",
                "yellow": "Informal awareness but no systematic verification process",
                "red": "No distinction between AI and human communications or verification procedures"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "How do employees know when they're interacting with AI versus humans in your systems?",
                  "evidence_type": "transparency_assessment"
                },
                {
                  "type": "Follow-up",
                  "text": "Have you had situations where employees were confused about whether they were talking to AI or a person?",
                  "evidence_type": "ambiguity_examples"
                }
              ]
            },
            {
              "type": "question",
              "id": "conv_q2",
              "text": "What's your procedure when employees report feeling 'something seems off' about digital communications, even if they can't pinpoint why? Give us a recent example where an employee had this gut feeling about a message or interaction.",
              "scoring_guidance": {
                "green": "Formal investigation protocol with recent example of successful gut-feeling escalation",
                "yellow": "Informal handling without systematic process",
                "red": "No protocol or dismissal of intuitive concerns without concrete evidence"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "Do you encourage or discourage employees from reporting when something 'just feels wrong' even without proof?",
                  "evidence_type": "reporting_culture"
                }
              ]
            }
          ]
        },
        {
          "title": "Colleague Verification and Training",
          "weight": 0.3,
          "items": [
            {
              "type": "question",
              "id": "conv_q3",
              "text": "How often do employees ask colleagues to verify whether communications are from humans or AI systems? Tell us about the last time this happened and how it was handled.",
              "scoring_guidance": {
                "green": "Regular verification requests with documented process and recent example",
                "yellow": "Occasional verification but no formal tracking or process",
                "red": "Rare or never - employees don't seek verification for AI-human ambiguity"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "Is asking for this kind of verification seen as normal or does it raise eyebrows?",
                  "evidence_type": "cultural_acceptance"
                }
              ]
            },
            {
              "type": "question",
              "id": "conv_q4",
              "text": "What's your policy for employees who express discomfort or confusion about whether they're interacting with AI systems versus humans in work communications? Provide a specific example of how your team handled such a situation.",
              "scoring_guidance": {
                "green": "Supportive policy with specific handling example showing employee protection",
                "yellow": "Limited support, acknowledged but no formal procedures",
                "red": "No policy or discomfort dismissed as overreaction to technology"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "Have employees ever been criticized for being 'too suspicious' of AI communications?",
                  "evidence_type": "psychological_safety"
                }
              ]
            },
            {
              "type": "question",
              "id": "conv_q5",
              "text": "How does your organization train employees to distinguish between legitimate AI security tools and potentially malicious AI-generated communications? Tell us about your most recent training session or guidance on this topic.",
              "scoring_guidance": {
                "green": "Comprehensive training with specific examples and recent session details",
                "yellow": "Basic awareness without specific AI detection skills",
                "red": "No training on distinguishing legitimate vs malicious AI"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "Does your training include examples of deepfakes or sophisticated AI-generated content?",
                  "evidence_type": "training_content_quality"
                }
              ]
            }
          ]
        },
        {
          "title": "Video Verification and Escalation",
          "weight": 0.35,
          "items": [
            {
              "type": "question",
              "id": "conv_q6",
              "text": "What happens when employees receive video calls or messages that look almost real but something feels 'wrong' about the person's appearance or behavior? Give us an example of how your team would handle a suspicious video communication.",
              "scoring_guidance": {
                "green": "Clear protocol with multi-factor verification and hypothetical/actual example",
                "yellow": "Informal awareness but no formal deepfake verification process",
                "red": "No protocol or assumption that video means legitimate communication"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "Do you have any technical tools for detecting deepfakes or manipulated video?",
                  "evidence_type": "technical_controls"
                },
                {
                  "type": "Follow-up",
                  "text": "What's the backup verification method if video authenticity is questioned?",
                  "evidence_type": "alternative_verification"
                }
              ]
            },
            {
              "type": "question",
              "id": "conv_q7",
              "text": "How quickly can employees escalate concerns about AI-human ambiguity in communications to security teams? Tell us about your escalation process and provide a recent example.",
              "scoring_guidance": {
                "green": "Fast escalation (<30 min) with documented process and recent example",
                "yellow": "Moderate speed (1-4 hours) or unclear escalation path",
                "red": "Slow escalation (>4 hours) or no clear process for AI ambiguity concerns"
              },
              "followups": [
                {
                  "type": "Follow-up",
                  "text": "Is there a dedicated channel or process specifically for reporting uncanny or suspicious AI interactions?",
                  "evidence_type": "specialized_channel"
                }
              ]
            }
          ]
        },
        {
          "title": "Probing for Red Flags",
          "weight": 0,
          "description": "Observable indicators that increase vulnerability score regardless of stated policies",
          "items": [
            {
              "type": "checkbox",
              "id": "red_flag_1",
              "label": "\"We don't have procedures for AI-human verification - it's not a real problem...\"",
              "severity": "critical",
              "score_impact": 0.16,
              "subitems": []
            },
            {
              "type": "checkbox",
              "id": "red_flag_2",
              "label": "\"Employees who report 'gut feelings' about communications are being overly paranoid...\"",
              "severity": "critical",
              "score_impact": 0.15,
              "subitems": []
            },
            {
              "type": "checkbox",
              "id": "red_flag_3",
              "label": "\"We can't tell the difference between AI and human communications and don't think we need to...\"",
              "severity": "high",
              "score_impact": 0.14,
              "subitems": []
            },
            {
              "type": "checkbox",
              "id": "red_flag_4",
              "label": "\"Video calls are always authentic - we don't worry about deepfakes...\"",
              "severity": "high",
              "score_impact": 0.13,
              "subitems": []
            },
            {
              "type": "checkbox",
              "id": "red_flag_5",
              "label": "\"No training on AI detection - we assume people can figure it out...\"",
              "severity": "high",
              "score_impact": 0.14,
              "subitems": []
            },
            {
              "type": "checkbox",
              "id": "red_flag_6",
              "label": "\"Escalation for AI ambiguity concerns takes hours or days - it's low priority...\"",
              "severity": "medium",
              "score_impact": 0.12,
              "subitems": []
            },
            {
              "type": "checkbox",
              "id": "red_flag_7",
              "label": "\"We've never had anyone report discomfort with AI communications...\" (suggests no reporting culture)\"",
              "severity": "medium",
              "score_impact": 0.11,
              "subitems": []
            }
          ]
        }
      ],
      "calculation": "Conversation_Score = Weighted_Average(subsection_scores) + Î£(red_flag_impacts)"
    }
  ],
  "validation": {
    "method": "matthews_correlation_coefficient",
    "formula": "V = (TPÂ·TN - FPÂ·FN) / sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))",
    "continuous_validation": {
      "synthetic_testing": "Inject uncanny AI communication scenarios monthly to test response protocols",
      "correlation_analysis": "Compare manual assessment with automated behavioral metrics (target correlation > 0.75)",
      "drift_detection": "Kolmogorov-Smirnov test on verification patterns, recalibrate if p < 0.05"
    },
    "calibration": {
      "method": "isotonic_regression",
      "description": "Ensure uncanny valley scores predict AI communication security incidents",
      "baseline_period": "90_days",
      "recalibration_trigger": "Drift detected or validation score < 0.70"
    },
    "success_metrics": [
      {
        "metric": "Verification Protocol Utilization Rate",
        "formula": "% of ambiguous AI communications that trigger verification procedures",
        "baseline": "current verification rate from employee surveys and system logs",
        "target": "80% improvement in verification usage within 90 days",
        "measurement": "monthly automated analysis of verification logs"
      },
      {
        "metric": "Uncanny Valley Escalation Response Time",
        "formula": "Time from employee uncertainty report to security team investigation completion",
        "baseline": "current response time from ticketing system",
        "target": "<30 minutes initial response, <2 hours investigation completion",
        "measurement": "continuous monitoring of ticketing timestamps"
      },
      {
        "metric": "False Trust Incident Reduction",
        "formula": "Security incidents where employees inappropriately trusted AI-generated communications",
        "baseline": "current incident rate from security reports",
        "target": "70% reduction within 90 days",
        "measurement": "quarterly incident analysis and employee feedback surveys"
      }
    ]
  },
  "remediation": {
    "solutions": [
      {
        "id": "sol_1",
        "title": "AI Communication Labeling Protocol",
        "description": "Implement mandatory labeling system for all AI-generated communications",
        "implementation": "Deploy technical controls that automatically tag AI messages with clear identifiers. Establish verification requirements for any unlabeled communications claiming human origin. Create escalation pathway for communications that lack proper AI/human identification.",
        "technical_controls": "Automated AI message tagging, identity verification system, unlabeled communication flags",
        "roi": "305% average within 12 months",
        "effort": "medium",
        "timeline": "45-60 days"
      },
      {
        "id": "sol_2",
        "title": "Uncanny Valley Response Training",
        "description": "Develop 20-minute training module teaching employees to recognize and trust their 'uncanny' feelings",
        "implementation": "Include practical exercises using examples of legitimate vs malicious AI communications. Train employees to use verification protocols when experiencing psychological discomfort with digital interactions. Provide clear scripts for escalating 'something feels wrong' concerns to security teams.",
        "technical_controls": "Training platform with scenario library, competency tracking, escalation scripts",
        "roi": "265% average within 18 months",
        "effort": "low",
        "timeline": "30 days initial, quarterly updates"
      },
      {
        "id": "sol_3",
        "title": "Two-Channel Verification System",
        "description": "Establish policy requiring verification through separate communication channel for any high-stakes requests",
        "implementation": "Implement technical system that automatically prompts verification for financial, access, or sensitive data requests. Create simple process for employees to quickly verify human identity through alternative means. Deploy phone or in-person verification requirements for unusual requests, regardless of source authenticity.",
        "technical_controls": "Dual-channel verification automation, alternative verification methods, high-risk flagging",
        "roi": "330% average within 12 months",
        "effort": "medium",
        "timeline": "45 days"
      },
      {
        "id": "sol_4",
        "title": "Psychological Safety Protocols",
        "description": "Create formal process for employees to report 'uncanny' or uncomfortable digital interactions without judgment",
        "implementation": "Establish security team response procedure for investigating ambiguous AI-human communications. Implement policy protecting employees who escalate based on intuitive concerns rather than technical evidence. Deploy rapid-response system for employees experiencing confusion about communication authenticity.",
        "technical_controls": "Anonymous reporting portal, rapid response ticketing, protection policy enforcement",
        "roi": "245% average within 18 months",
        "effort": "low",
        "timeline": "30 days"
      },
      {
        "id": "sol_5",
        "title": "AI Interaction Baseline Monitoring",
        "description": "Deploy system to monitor patterns in employee responses to AI communications",
        "implementation": "Establish baseline metrics for normal AI interaction behaviors (response times, verification requests, escalations). Create alerts for unusual patterns that might indicate uncanny valley exploitation. Implement automated detection for communication patterns that typically trigger uncanny valley responses.",
        "technical_controls": "Behavioral analytics platform, baseline tracking, anomaly detection, alert system",
        "roi": "290% average within 12 months",
        "effort": "high",
        "timeline": "60-90 days"
      },
      {
        "id": "sol_6",
        "title": "Enhanced Authentication for Ambiguous Communications",
        "description": "Deploy multi-factor verification system triggered by employee uncertainty reports",
        "implementation": "Implement biometric or behavioral authentication for video/audio communications when requested. Create technical controls that flag communications exhibiting uncanny valley characteristics. Establish secure verification codes or phrases for confirming human identity in suspicious interactions.",
        "technical_controls": "Multi-factor authentication, biometric verification, deepfake detection integration",
        "roi": "315% average within 12 months",
        "effort": "high",
        "timeline": "60-90 days"
      }
    ],
    "prioritization": {
      "critical_first": [
        "sol_1",
        "sol_3"
      ],
      "high_value": [
        "sol_6",
        "sol_5"
      ],
      "cultural_foundation": [
        "sol_2",
        "sol_4"
      ],
      "governance": [
        "sol_1"
      ]
    }
  },
  "risk_scenarios": [
    {
      "id": "multi_vector_attack_exploitation",
      "title": "Multi-Vector Attack During Organizational Stress",
      "description": "Attackers launch simultaneous attacks against multiple systems knowing that overwhelmed IT teams will make mistakes, delay responses, or bypass security controls. During the chaos, lateral movement and data exfiltration proceed unnoticed as normal monitoring and coordination break down.",
      "likelihood": "medium-high",
      "impact": "critical",
      "attack_pattern": {
        "reconnaissance": "Attackers identify organizational stress periods through social media, press releases, job postings, and public incident disclosures indicating high operational load",
        "timing": "Attack launched during confirmed stress period (quarter-end, major migration, leadership transition, or concurrent with legitimate operational incidents)",
        "execution": "Simultaneous attacks across multiple vectors: (1) Phishing targeting finance during quarter-end, (2) Vulnerability exploitation on systems under maintenance, (3) Social engineering against help desk claiming to be traveling executives, (4) DDoS against monitoring systems",
        "exploitation": "While security team attempts to triage which threat to prioritize and coordinate response across teams, attackers achieve objectives across multiple vectors before effective coordinated response can form. Communication breakdown prevents teams from recognizing coordinated nature of attacks."
      },
      "real_world_examples": [
        "Target 2013: Holiday season stress + vendor management chaos + POS deployment enabled both HVAC compromise and payment system data exfiltration to proceed undetected",
        "Ukrainian power grid 2015: Attackers coordinated technical attacks with telephone denial-of-service against support lines during winter response stress"
      ],
      "indicators": [
        "Unusually high volume of security alerts across multiple categories during known high-stress organizational period",
        "Multiple simultaneous requests for security policy exceptions from different departments",
        "Help desk volume spike with urgent requests during known crisis period",
        "Correlation between external attacks and internal operational stress indicators"
      ],
      "mitigation_mapping": {
        "incident_command_system": "Enables coordinated response across multiple simultaneous threats preventing cascade from overwhelming individual teams",
        "crisis_communication_redundancy": "Maintains communication effectiveness preventing attackers from exploiting communication overload",
        "dependency_mapping_circuit_breakers": "Isolates compromised systems preventing lateral movement during cascade conditions"
      }
    },
    {
      "id": "social_engineering_crisis",
      "title": "Social Engineering During Legitimate Crisis",
      "description": "Attackers exploit organizational stress by impersonating executives or vendors during legitimate crisis periods (layoffs, mergers, system outages, incidents). Stressed employees bypass verification procedures and provide access or information they normally would question, with bypasses spreading to other employees through stress contagion.",
      "likelihood": "high",
      "impact": "high",
      "attack_pattern": {
        "reconnaissance": "Attackers monitor target organization for crisis indicators (press releases, social media complaints, public incidents, regulatory filings indicating organizational stress)",
        "timing": "Social engineering initiated during confirmed crisis when normal verification procedures are likely bypassed due to stress and urgency",
        "execution": "Attackers impersonate executives or vendors making urgent requests leveraging the legitimate crisis. Initial successful social engineering spreads as stressed employees inform others that 'exceptions are being made' or 'we need to move fast'. Stress contagion causes cascade of verification bypasses.",
        "exploitation": "Multiple employees provide access, credentials, or sensitive information. Each successful social engineering attack reduces other employees' resistance as they observe colleagues making exceptions. Cascade of security control bypasses provides attackers extensive access before detection."
      },
      "real_world_examples": [
        "Twitter 2020: Attackers used social engineering during operational stress to compromise employee credentials, leading to cascade of additional compromises as standard verification procedures broke down",
        "Ubiquiti Networks 2015: Social engineering during busy quarter-ends when oversight was minimal enabled fraudulent wire transfers"
      ],
      "indicators": [
        "Spike in help desk requests for emergency access during organizational crisis periods",
        "Multiple employees reporting urgent requests from executives during the same timeframe",
        "Pattern of security verification procedures bypassed during specific stress periods",
        "Employees mentioning that 'others already approved similar requests' as justification"
      ],
      "mitigation_mapping": {
        "automated_exception_tracking": "Provides visibility when exception volume spikes indicating possible social engineering cascade",
        "executive_crisis_training": "Leaders trained to maintain verification procedures and communicate clearly during crisis preventing social engineering pretexts",
        "stress_testing_exercises": "Practice scenarios specifically testing resistance to social engineering during simulated stress"
      }
    },
    {
      "id": "insider_threat_amplification",
      "title": "Insider Threat Exploitation During Organizational Turmoil",
      "description": "Disgruntled employees or malicious insiders exploit periods of organizational turmoil when oversight is reduced and management attention is divided. They leverage their knowledge of how the organization responds poorly to stress to cover malicious activities while security teams are overwhelmed.",
      "likelihood": "medium",
      "impact": "high",
      "attack_pattern": {
        "reconnaissance": "Insider observes organizational stress patterns and identifies when oversight mechanisms predictably break down (during major incidents, layoffs, leadership transitions, merger activities)",
        "timing": "Malicious actions initiated when cascade conditions are evident - multiple simultaneous organizational stressors with visible communication breakdown and overwhelmed security teams",
        "execution": "Insider requests emergency access exceptions or elevated privileges using urgent business justifications that would normally face scrutiny but are approved rapidly during crisis. Alternatively, takes actions knowing monitoring is degraded during stress periods. May deliberately create additional minor incidents to further overwhelm security teams.",
        "exploitation": "Unauthorized data access, exfiltration, system modification, or sabotage occurs during window when emergency processes replace normal controls and detection/response capacity is consumed by legitimate crisis handling. Cascade of security control bypasses provides cover for insider malicious activity."
      },
      "real_world_examples": [
        "Ubiquiti Networks 2015: Insider exploited periods of minimal oversight during busy quarter-ends to conduct fraudulent wire transfers totaling $46.7 million",
        "Tesla 2020: Insider recruited during COVID-19 transition when normal oversight mechanisms were disrupted by remote work stress"
      ],
      "indicators": [
        "Access or permission requests using urgent business justifications during known high-stress periods from employees with performance or behavioral concerns",
        "Unusual data access patterns coinciding with organizational crisis periods from users with elevated privileges",
        "Emergency access approvals granted by non-standard approvers during stress periods",
        "Pattern of minor incidents or alerts during stress periods that may be deliberately created as distraction"
      ],
      "mitigation_mapping": {
        "automated_exception_tracking": "Ensures urgent access requests receive appropriate scrutiny and tracking even during stress periods",
        "dependency_mapping_circuit_breakers": "Limits scope of potential insider damage through isolation mechanisms",
        "incident_command_system": "Maintains oversight and coordination even during stress preventing insider exploitation of chaos"
      }
    },
    {
      "id": "supply_chain_vendor_crisis",
      "title": "Supply Chain Attack via Vendor Crisis Exploitation",
      "description": "Attackers compromise vendors during their crisis periods (system upgrades, staffing changes, financial stress), then use compromised vendor access to infiltrate primary targets when internal security teams are already overwhelmed, creating cross-organizational cascade failures.",
      "likelihood": "medium",
      "impact": "critical",
      "attack_pattern": {
        "reconnaissance": "Attackers identify critical vendors and monitor for stress indicators (press releases about layoffs, social media indicating system problems, job postings indicating security team turnover, financial stress indicators)",
        "timing": "Initial vendor compromise occurs during vendor's crisis period. Attacks on vendor's customers are timed to coincide with customer organization stress periods creating cross-organizational cascade",
        "execution": "Attackers establish persistence in compromised vendor environment during vendor crisis when detection is impaired. Leverage trusted vendor relationships to attack downstream customers who are simultaneously dealing with their own organizational stress. Vendor's compromised state prevents them from detecting or reporting malicious use of their access to customers.",
        "exploitation": "Customer organizations fail to detect vendor-sourced attacks because: (1) vendor channels are trusted and bypass normal scrutiny, (2) customer security teams overwhelmed with internal issues, (3) normal vendor verification processes bypassed during urgency, (4) cascade effects in both vendor and customer create extended detection and response delays"
      },
      "real_world_examples": [
        "SolarWinds 2020: Initial compromise during rapid COVID-19 digital transformation stress; customers simultaneously dealing with remote work security challenges creating cross-organizational cascade",
        "Kaseya 2021: Ransomware supply chain attack deployed during July 4th weekend when many security teams understaffed creating temporal cascade"
      ],
      "indicators": [
        "Unusual vendor communications or access requests during periods of known vendor organizational stress",
        "Vendor requests for emergency access or elevated privileges coinciding with vendor public stress indicators",
        "Changes in vendor communication patterns, contacts, or procedures during customer high-stress periods",
        "Vendor-sourced updates or activities occurring during unusual timing (holidays, weekends, known customer stress periods)"
      ],
      "mitigation_mapping": {
        "crisis_communication_redundancy": "Maintains vendor verification protocols through backup communication channels even during stress",
        "automated_exception_tracking": "Ensures vendor-related security decisions receive appropriate scrutiny regardless of urgency",
        "dependency_mapping_circuit_breakers": "Limits vendor access scope reducing potential cascade impact from compromised vendor"
      }
    }
  ],
  "metadata": {
    "language": "en-US",
    "language_name": "English (United States)",
    "is_translation": false,
    "translated_from": null,
    "translation_date": null,
    "translator": null,
    "created_date": "2025-11-08",
    "last_modified": "2025-11-08",
    "version_history": [
      {
        "version": "1.0",
        "date": "2025-11-08",
        "changes": "Initial release - Category 10.x batch generation",
        "author": "CPF Development Team"
      }
    ]
  }
}