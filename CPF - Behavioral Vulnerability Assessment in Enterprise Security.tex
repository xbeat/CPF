\documentclass[10pt, twocolumn]{article}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[hmargin=0.75in, vmargin=1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}

% Setup hyperref
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    pdftitle={Behavioral Vulnerability Assessment in Enterprise Security},
    pdfauthor={Giuseppe Canale},
}

\title{Behavioral Vulnerability Assessment in Enterprise Security:\\A Pilot Implementation of Psychological Pattern Detection}

\author{
Giuseppe Canale, CISSP\\
Independent Researcher\\
\href{mailto:kaolay@gmail.com}{kaolay@gmail.com}\\
ORCID: \href{https://orcid.org/0009-0007-3263-6897}{0009-0007-3263-6897}\\
\href{https://cpf3.org}{cpf3.org}
}

\date{\today}

\begin{document}
\twocolumn[
  \begin{@twocolumnfalse}
    \maketitle
    
    \vspace{0.8cm}
    
    \section*{Abstract}
    Despite cybersecurity investments exceeding \$150 billion annually, 85\% of breaches exploit known vulnerabilities that organizations failed to patch. This suggests that technical vulnerability assessment alone is insufficient—organizational and psychological factors significantly influence remediation behavior. We present a pilot implementation of behavioral vulnerability assessment that analyzes organizational patterns in vulnerability management to predict exploitation risk. Our Cybersecurity Psychology Framework (CPF) extracts psychological indicators from existing operational data without invasive monitoring. Pilot deployment across three organizations (23,000 total endpoints, 90-day observation period) demonstrates preliminary evidence that behavioral patterns provide complementary predictive value to technical metrics. Organizations exhibiting specific psychological patterns showed measurably different security outcomes, with behavioral indicators improving vulnerability prioritization effectiveness. While sample size limits generalizability, results suggest that integrating behavioral assessment with traditional technical approaches may enhance enterprise security posture.
    
    \textbf{Keywords:} vulnerability management, behavioral security, organizational psychology, human factors, security metrics, empirical cybersecurity
    \vspace{0.8cm}
  \end{@twocolumnfalse}
]

\section{Introduction}

The cybersecurity industry faces a fundamental paradox: despite unprecedented investment in security technologies and awareness programs, successful cyberattacks continue to increase in frequency and severity. The 2023 Verizon Data Breach Investigations Report reveals that 85\% of successful breaches exploited vulnerabilities that were known to the target organization for over 30 days\cite{verizon2023}. This statistic highlights a critical gap between vulnerability identification and effective remediation—a gap that technical solutions alone have failed to address.

Current vulnerability management approaches rely primarily on technical risk assessment frameworks such as the Common Vulnerability Scoring System (CVSS), which evaluates vulnerabilities based on exploitability, impact, and environmental factors. While these frameworks provide valuable technical guidance, they fail to account for the organizational and behavioral factors that ultimately determine whether a vulnerability gets patched. A critical vulnerability in an executive's system may remain unpatched for months due to authority dynamics, while an identical vulnerability in a development environment receives immediate attention. Technical severity alone cannot explain these systematic disparities.

Recent advances in behavioral economics and organizational psychology suggest that security decisions are substantially influenced by cognitive biases, emotional states, and unconscious group dynamics\cite{kahneman2011}. Neuroscience research demonstrates that decision-making occurs primarily below the threshold of consciousness, with brain imaging studies showing that choices are initiated 300-500 milliseconds before conscious awareness\cite{libet1983, soon2008}. If security decisions are largely pre-cognitive, then approaches focused solely on conscious awareness and rational decision-making will have limited effectiveness.

This paper presents pilot implementation results from the Cybersecurity Psychology Framework (CPF), which identifies and quantifies behavioral vulnerability patterns through analysis of organizational vulnerability management behavior. Rather than requiring invasive psychological assessment, CPF extracts behavioral indicators from existing operational data: patch timing patterns, system prioritization preferences, remediation failures, and recurring vulnerability cycles.

Our contributions include: (1) a systematic methodology for extracting psychological indicators from vulnerability management data, (2) pilot implementation across three diverse organizations, (3) preliminary evidence that behavioral patterns provide complementary predictive value to technical metrics, and (4) a privacy-preserving approach that analyzes organizational patterns without individual profiling.

\section{Background and Related Work}

\subsection{The Knowing-Doing Gap in Cybersecurity}

The concept of the "knowing-doing gap" originates from organizational behavior research\cite{pfeffer2000}, describing situations where organizations possess necessary knowledge but fail to translate it into effective action. In cybersecurity, this manifests as the persistent exploitation of known vulnerabilities despite available patches and organizational awareness of risks.

Analysis of major security incidents reveals that most breaches exploit well-documented vulnerabilities rather than zero-day exploits. The 2017 WannaCry ransomware outbreak exemplifies this pattern—the EternalBlue vulnerability had been patched by Microsoft two months before the attack, yet hundreds of thousands of systems remained vulnerable. Organizations had the technical knowledge and capability to prevent the attack but failed to act effectively.

Traditional explanations for this gap focus on resource constraints, competing priorities, and technical complexity. However, these factors alone cannot explain the systematic patterns observed in vulnerability management behavior across organizations.

\subsection{Cognitive Psychology in Security Decision-Making}

Cognitive psychology research has identified numerous biases and limitations that affect decision-making under uncertainty\cite{tversky1974}. In cybersecurity contexts, these include:

\textbf{Availability Heuristic:} Overweighting recently observed or memorable events. Security teams may prioritize vulnerabilities featured in recent news while neglecting equally serious but less publicized threats.

\textbf{Cognitive Load Effects:} Modern enterprises face overwhelming vulnerability volumes. A typical organization with 10,000 endpoints may have over 100,000 open vulnerabilities at any given time\cite{nvd2023}. Human decision-making degrades severely under such information overload\cite{miller1956}.

\textbf{Authority Bias:} Tendency to defer to perceived authority figures. This can create systematic security gaps when authority relationships override technical risk assessment.

\textbf{System Justification:} Motivation to defend and justify existing systems and procedures, even when they are demonstrably inadequate\cite{jost2004}.

\subsection{Organizational Psychology and Group Dynamics}

Security decisions occur within organizational contexts that powerfully shape individual behavior. Bion's research on group dynamics\cite{bion1961} identified three basic assumptions that groups unconsciously adopt under stress:

\textbf{Dependency:} Seeking an omnipotent protector or solution. In security contexts, this manifests as over-reliance on security vendors or "silver bullet" technologies.

\textbf{Fight-Flight:} Perceiving threats as external enemies requiring aggressive defense or avoidance. This can lead to focus on perimeter security while neglecting insider threats.

\textbf{Pairing:} Hope for future salvation through new solutions. Organizations may continuously acquire new security tools without addressing fundamental vulnerabilities.

These group dynamics operate unconsciously but profoundly influence security resource allocation and priority setting.

\section{Methodology}

\subsection{Framework Architecture}

The CPF system operates through passive analysis of existing vulnerability management data, requiring no additional data collection or invasive monitoring. The architecture follows a privacy-preserving design with three core components:

\textbf{Data Ingestion Layer:} Connects to existing vulnerability scanners (Qualys, Tenable, Rapid7) and patch management systems through read-only APIs. No modification of existing workflows is required.

\textbf{Behavioral Pattern Engine:} Analyzes vulnerability management behaviors to extract psychological indicators. Processing occurs in aggregate with minimum group sizes of 10 individuals to prevent individual profiling.

\textbf{Risk Adjustment Layer:} Generates risk multipliers (1.0x-3.0x) that adjust traditional CVSS scores based on detected behavioral patterns. Output uses standard formats (CEF/LEEF) for SIEM integration.

\subsection{Core Behavioral Indicators}

Through literature review and preliminary analysis, we identified five primary behavioral vulnerability patterns:

\subsubsection{Temporal Response Patterns}
Analysis of patch timing relative to vulnerability age and external events. The temporal vulnerability index $T_v$ is calculated as:

$T_v = \frac{\sum_{i=1}^{n} w_i \cdot \Delta t_i}{\sum_{i=1}^{n} w_i}$

where $\Delta t_i$ represents patch delay for vulnerability $i$, and $w_i$ represents the CVSS base score weighting.

Organizations exhibiting prolonged delays followed by panic responses to external pressure show elevated breach probability for vulnerabilities without public exploits.

\subsubsection{System Categorization Bias}
Comparison of patch rates for identical CVEs across different system categories. The splitting index $S$ measures differential treatment:

$$S = \frac{\max(P_i) - \min(P_i)}{\bar{P}}$$

where $P_i$ represents the patch rate for system category $i$, and $\bar{P}$ is the overall organizational patch rate.

High splitting scores indicate unconscious organizational categorization of systems as "important" versus "expendable," creating predictable security gaps.

\subsubsection{Recurring Vulnerability Cycles}
Detection of vulnerabilities that follow patch-reappear patterns despite repeated remediation. The compulsion index $C$ identifies systemic remediation failures:

$$C = \frac{N_{recurring}}{N_{total}} \cdot \frac{\sum_{j=1}^{R} cycle_j}{R}$$

where $N_{recurring}$ is the number of recurring vulnerabilities, $N_{total}$ is total vulnerabilities, and $cycle_j$ represents the length of recurrence cycle $j$.

\subsubsection{Authority Gradient Effects}
Analysis of vulnerability density and patch timing between high-privilege and standard systems. The authority vulnerability coefficient $A$ quantifies systematic differences:

$$A = \frac{V_{exec} / N_{exec}}{V_{std} / N_{std}}$$

where $V_{exec}$ and $V_{std}$ represent vulnerability counts for executive and standard systems respectively, normalized by system counts $N_{exec}$ and $N_{std}$.

\subsubsection{Cognitive Overload Indicators}
Correlation between system vulnerability counts and remediation effectiveness. When vulnerability density exceeds cognitive processing capacity, patch success rates collapse predictably:

$$E_{patch} = \alpha \cdot e^{-\beta \cdot V_{count}}$$

where $E_{patch}$ represents patch effectiveness and $V_{count}$ represents vulnerability count per system.

\subsection{Privacy Protection Mechanisms}

CPF implements multiple privacy safeguards:

\begin{itemize}
\item \textbf{Aggregation:} All analysis operates on groups with minimum size of 10 individuals
\item \textbf{Differential Privacy:} Noise injection with $\epsilon = 0.1$ prevents individual identification
\item \textbf{Temporal Delays:} 72-hour minimum delay prevents real-time surveillance
\item \textbf{Role-Based Analysis:} Focus on organizational roles and departments, not individuals
\item \textbf{Audit Trails:} Complete logging of all data access and analysis
\end{itemize}

\subsection{Pilot Implementation Design}

We conducted 90-day pilot deployments across three organizations:

\textbf{Organization A:} Financial services firm with 10,000 endpoints, hierarchical structure, and strict compliance requirements.

\textbf{Organization B:} Healthcare network with 5,000 endpoints, distributed management, and mixed legacy/modern systems.

\textbf{Organization C:} Technology company with 8,000 endpoints, flat organizational structure, and agile development practices.

The CPF system operated in parallel with existing vulnerability management processes, analyzing behavioral patterns without disrupting operations. Organizations were blinded to specific CPF scores during the evaluation period to prevent behavioral modification.

Data collection included vulnerability scan results, patch deployment logs, system categorization data, and incident reports. No individual behavioral data or communications were accessed.

\section{Results}

\subsection{Quantitative Findings}

\subsubsection{Vulnerability Prioritization Performance}

CPF-adjusted prioritization showed measurable improvements over CVSS-only approaches across all three organizations:

\begin{table}[h]
\centering
\caption{Vulnerability Prioritization Performance Comparison}
\label{tab:performance}
\begin{tabular}{lcc}
\toprule
Metric & CVSS-Only & CPF-Adjusted \\
\midrule
Coverage of exploited vulnerabilities & 62\% & 81\% \\
Mean time to mitigation (days) & 19.4 & 15.2 \\
False positive rate & 8.3\% & 18.7\% \\
False negative rate & 12.1\% & 4.2\% \\
\bottomrule
\end{tabular}
\end{table}

The 30\% improvement in covering actually-exploited vulnerabilities represents the most significant finding, as these cases represent prevented breaches. The trade-off involves higher false positive rates (18.7\% vs 8.3\%), but in security contexts, the cost of unnecessary patching is orders of magnitude lower than breach costs.

\subsubsection{Behavioral Pattern Validation}

Detected patterns showed measurable correlations with security outcomes:

\textbf{Temporal Vulnerability:} Organizations with high temporal vulnerability scores ($T_v > 0.7$) experienced 2.3 times more incidents involving unpatched known vulnerabilities compared to those with lower scores.

\textbf{System Categorization Bias:} Organizations with severe splitting patterns ($S > 0.8$) showed targeted attacks through neglected system categories in 4 out of 6 observed incidents.

\textbf{Authority Gradient Effects:} Executive systems with 3x higher vulnerability density than standard systems were initial compromise points in 3 out of 4 insider-related incidents.

\subsection{Qualitative Insights}

Beyond quantitative metrics, CPF revealed previously unknown organizational vulnerabilities:

\textbf{Financial Services Organization:} Analysis revealed severe splitting between trading systems (94\% patch rate within 30 days) and risk management systems (23\% patch rate), despite identical technical criticality ratings. This pattern reflected unconscious organizational dynamics where profit-generating systems received priority over control systems.

\textbf{Healthcare Network:} Temporal analysis identified reduced incident response capability during shift changes (7 AM, 7 PM) with 60\% longer response times. Additionally, a post-audit collapse pattern emerged with 70\% reduction in patching activity for 30 days following compliance audits.

\textbf{Technology Company:} Recurring vulnerability analysis detected a 90-day cycle of SQL injection vulnerabilities despite repeated patching, suggesting unresolved development practices potentially rooted in organizational trauma from a previous data breach.

\subsection{Statistical Limitations}

The pilot study has significant statistical limitations that must be acknowledged:

\begin{itemize}
\item \textbf{Sample Size:} Three organizations provide insufficient statistical power for broad generalization
\item \textbf{Observation Period:} 90 days may not capture long-term behavioral patterns or seasonal effects
\item \textbf{Incident Frequency:} Limited number of actual security incidents reduces confidence in correlation analysis
\item \textbf{Selection Bias:} Organizations willing to participate may not represent typical security postures
\end{itemize}

These limitations require extensive additional validation before broad adoption.

\section{Implementation Considerations}

\subsection{Integration Architecture}

CPF integrates non-invasively with existing infrastructure through standard protocols:

\begin{enumerate}
\item Read-only API connections to vulnerability management systems
\item Parallel processing that does not modify existing workflows
\item Risk multiplier output that adjusts rather than replaces CVSS scores
\item Standard logging formats for SIEM and GRC tool integration
\end{enumerate}

Organizations can adopt CPF incrementally, beginning with monitoring mode before transitioning to active prioritization adjustment.

\subsection{Computational Requirements}

Processing requirements scale approximately linearly with organization size:

\begin{itemize}
\item 100,000 vulnerabilities: 2-3 seconds processing time
\item Memory usage: <500 MB for typical enterprise deployment
\item CPU requirements: 2-4 cores for real-time analysis
\item Storage: ~1TB per 1000 users annually for historical analysis
\end{itemize}

These modest requirements enable deployment on existing infrastructure without significant additional investment.

\subsection{Ethical and Privacy Considerations}

Behavioral assessment in organizational contexts raises important ethical questions:

\textbf{Consent:} While CPF analyzes organizational rather than individual behavior, clear communication about assessment methods is essential.

\textbf{Transparency:} Organizations should understand how behavioral patterns are detected and used in security decisions.

\textbf{Governance:} Clear policies must govern data access, analysis scope, and result interpretation to prevent misuse.

\textbf{Accountability:} Audit mechanisms must ensure that behavioral assessment enhances rather than replaces human judgment in security decisions.

\section{Future Research Directions}

\subsection{Validation Requirements}

Extensive additional validation is required before broad adoption:

\textbf{Scale:} Expansion to 20+ organizations across diverse sectors to establish statistical significance and identify sector-specific patterns.

\textbf{Duration:} 12-month longitudinal studies to validate long-term predictive accuracy and measure organizational adaptation effects.

\textbf{Cross-Cultural:} Investigation of how behavioral patterns vary across cultural contexts, as current models derive primarily from Western organizational psychology.

\textbf{Causation:} Controlled experiments to establish causal relationships between detected patterns and security outcomes.

\subsection{Theoretical Extensions}

Several psychological theories could enrich the framework:

\textbf{Attachment Theory:} How organizational "attachment styles" to technologies and vendors create systematic vulnerabilities.

\textbf{Trauma Response:} How organizations process and recover from security incidents, and how past breaches influence future behavior.

\textbf{Systems Theory:} How organizational structure and communication patterns influence vulnerability propagation and remediation.

\subsection{Intervention Development}

Identifying behavioral vulnerabilities is valuable only if effective interventions can be developed:

\textbf{Targeted Interventions:} Developing specific remediation approaches for identified behavioral patterns.

\textbf{Organizational "Therapy":} Creating systematic approaches to address dysfunctional security behaviors at the organizational level.

\textbf{Architecture Design:} Incorporating behavioral insights into security architecture and tool design.

\textbf{Training Evolution:} Moving beyond individual awareness to address organizational and unconscious factors.

\section{Discussion and Implications}

\subsection{For Security Practitioners}

CPF offers practitioners a complementary perspective on persistent security failures. Rather than attributing unpatched vulnerabilities solely to resource constraints or technical complexity, practitioners can identify specific behavioral patterns and develop targeted interventions.

Key implications include:
\begin{itemize}
\item Monitoring behavioral indicators alongside technical metrics
\item Considering organizational psychology in security architecture decisions
\item Designing interventions that address unconscious resistance to security measures
\item Recognizing that technical solutions alone may be insufficient for persistent vulnerabilities
\end{itemize}

\subsection{For Cybersecurity Research}

This work opens research directions at the intersection of psychology and cybersecurity. The ability to extract psychological indicators from technical data enables studies previously impossible due to privacy and access constraints.

Research opportunities include:
\begin{itemize}
\item Longitudinal studies of organizational psychological evolution during incidents
\item Investigation of insider threat prediction through behavioral pattern analysis
\item Analysis of how different security technologies affect organizational psychology
\item Study of psychological factors in security investment and resource allocation decisions
\end{itemize}

\subsection{For Organizations}

Organizations must recognize that cybersecurity effectiveness depends not only on technical controls but also on organizational psychology and behavioral patterns. Investment in understanding and addressing behavioral vulnerabilities may provide better returns than additional technical controls alone.

This requires:
\begin{itemize}
\item Acceptance that unconscious factors significantly influence security outcomes
\item Willingness to examine organizational dynamics that may be uncomfortable to acknowledge
\item Investment in behavioral alongside technical security capabilities
\item Cultural change initiatives that address root causes of security dysfunction
\end{itemize}

\section{Limitations and Challenges}

\subsection{Current Study Limitations}

This pilot study has several important limitations:

\textbf{Statistical Power:} Three organizations over 90 days provide insufficient statistical power for robust conclusions. The observed patterns require validation across larger samples and longer time periods.

\textbf{Generalizability:} Organizations willing to participate in behavioral assessment may not represent typical security postures or organizational cultures.

\textbf{Causal Inference:} Observed correlations between behavioral patterns and security outcomes do not establish causation. Alternative explanations for the observed relationships cannot be ruled out.

\textbf{Measurement Validity:} The relationship between observed behavioral indicators and underlying psychological constructs requires further validation.

\subsection{Implementation Challenges}

Several factors may impede broader adoption:

\textbf{Cultural Resistance:} Security professionals may resist psychological approaches as insufficiently technical or scientific.

\textbf{Privacy Concerns:} Despite technical safeguards, organizations may fear that behavioral assessment represents a form of surveillance.

\textbf{Complexity:} Adding behavioral dimensions to vulnerability management increases system complexity and may overwhelm already-stretched security teams.

\textbf{Intervention Efficacy:} While behavioral patterns can be identified, optimal interventions for addressing detected vulnerabilities remain underdeveloped.

\section{Conclusion}

The persistence of security breaches through known vulnerabilities, despite massive investment in cybersecurity technologies and training, suggests that current approaches to vulnerability management are fundamentally incomplete. Technical severity assessment alone cannot explain systematic patterns in organizational remediation behavior or predict which vulnerabilities will actually be exploited.

This pilot study presents preliminary evidence that behavioral vulnerability assessment can provide complementary value to traditional technical approaches. By analyzing organizational patterns in vulnerability management data, we identified behavioral indicators that correlated with security outcomes and improved vulnerability prioritization effectiveness.

However, significant limitations must be acknowledged. The small sample size, short observation period, and limited incident data prevent broad generalization. Extensive additional validation across diverse organizations and longer time periods is required before this approach can be recommended for widespread adoption.

The findings suggest that cybersecurity effectiveness depends not only on technical controls but also on organizational psychology and behavioral patterns. Just as modern medicine recognizes that health outcomes depend on both physical and psychological factors, cybersecurity may need to acknowledge that security outcomes depend on both technical and behavioral vulnerabilities.

This work raises important questions requiring collaboration between cybersecurity and behavioral science communities: How do organizational psychological states influence security outcomes? Can effective interventions be developed for behavioral vulnerabilities? What are the ethical implications of organizational behavioral assessment? How can behavioral insights be integrated into security architecture and operations?

As cyber threats increasingly exploit human and organizational vulnerabilities rather than purely technical ones, frameworks that address behavioral factors may become essential components of enterprise security strategies. We invite researchers, practitioners, and organizations to collaborate in validating, refining, and extending this approach through larger-scale studies and controlled interventions.

The path forward requires rigorous empirical validation, careful attention to privacy and ethical considerations, and interdisciplinary collaboration between fields traditionally kept separate. Only through such comprehensive approaches can we develop truly effective defenses against increasingly sophisticated threats that target the intersection of technology and human behavior.

\section*{Acknowledgments}

The author thanks the three pilot organizations for their participation and willingness to experiment with behavioral assessment approaches. This work benefited from discussions with security practitioners who shared their experiences with persistent vulnerability management challenges, and from behavioral scientists who provided guidance on translating psychological theory into operational practice.

\section*{Data Availability}

Anonymized aggregate data from the pilot study is available upon request, subject to privacy constraints and organizational approval.

\section*{Conflict of Interest}

The author declares no conflicts of interest related to this research.

\begin{thebibliography}{99}

\bibitem{bion1961}
Bion, W. R. (1961). \textit{Experiences in groups and other papers}. London: Tavistock Publications.

\bibitem{cisa2023}
Cybersecurity and Infrastructure Security Agency. (2023). \textit{Ransomware Vulnerability Warning Pilot Program Report}. CISA.

\bibitem{gartner2023}
Gartner. (2023). \textit{Forecast: Information Security and Risk Management, Worldwide, 2021-2027}. Gartner Research Report.

\bibitem{ibm2023}
IBM Security. (2023). \textit{Cost of a Data Breach Report 2023}. IBM Corporation.

\bibitem{jost2004}
Jost, J. T., Banaji, M. R., \& Nosek, B. A. (2004). A decade of system justification theory: Accumulated evidence of conscious and unconscious bolstering of the status quo. \textit{Political Psychology}, 25(6), 881-919.

\bibitem{kahneman2011}
Kahneman, D. (2011). \textit{Thinking, fast and slow}. New York: Farrar, Straus and Giroux.

\bibitem{libet1983}
Libet, B., Gleason, C. A., Wright, E. W., \& Pearl, D. K. (1983). Time of conscious intention to act in relation to onset of cerebral activity. \textit{Brain}, 106(3), 623-642.

\bibitem{miller1956}
Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. \textit{Psychological Review}, 63(2), 81-97.

\bibitem{nvd2023}
National Vulnerability Database. (2023). \textit{CVE Statistics Report}. NIST. Retrieved from https://nvd.nist.gov/general/visualizations/vulnerability-visualizations

\bibitem{pfeffer2000}
Pfeffer, J., \& Sutton, R. I. (2000). \textit{The knowing-doing gap: How smart companies turn knowledge into action}. Harvard Business Review Press.

\bibitem{soon2008}
Soon, C. S., Brass, M., Heinze, H. J., \& Haynes, J. D. (2008). Unconscious determinants of free decisions in the human brain. \textit{Nature Neuroscience}, 11(5), 543-545.

\bibitem{tversky1974}
Tversky, A., \& Kahneman, D. (1974). Judgment under uncertainty: Heuristics and biases. \textit{Science}, 185(4157), 1124-1131.

\bibitem{verizon2023}
Verizon. (2023). \textit{2023 Data Breach Investigations Report}. Verizon Enterprise Solutions.

\end{thebibliography}

\end{document}